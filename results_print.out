INFO:root:Evaluating the oracle outputs.
INFO:root:Creating the annotator from `oasst_pythia_12b`.
INFO:root:Saving annotations to `/u/hongli/.conda/envs/hongli/lib/python3.11/site-packages/alpaca_eval/evaluators_configs/oasst_pythia_12b/annotations_seed0_configs.json`.
INFO:root:Loading all annotations from /u/hongli/.conda/envs/hongli/lib/python3.11/site-packages/alpaca_eval/evaluators_configs/oasst_pythia_12b/annotations_seed0_configs.json.
Annotation chunk:   0%|          | 0/1 [00:00<?, ?it/s]INFO:root:Annotating 20 examples with oasst_pythia_12b
INFO:root:Using `huggingface_local_completions` on 20 prompts using OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s][A
Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:35<01:10, 35.16s/it][A
Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [01:08<00:34, 34.06s/it][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:19<00:00, 23.55s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:19<00:00, 26.50s/it]
The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.
INFO:root:Model memory: 47.53777704 GB
INFO:root:Kwargs to completion: {'do_sample': False, 'model_kwargs': {'device_map': 'auto'}, 'batch_size': 1, 'max_new_tokens': 50}

  0%|          | 0/20 [00:00<?, ?it/s][A
  5%|â–Œ         | 1/20 [00:04<01:31,  4.82s/it][A
 10%|â–ˆ         | 2/20 [00:05<00:39,  2.18s/it][A
 15%|â–ˆâ–Œ        | 3/20 [00:05<00:22,  1.33s/it][A
 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:15,  1.00it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:11,  1.33it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:06<00:08,  1.63it/s][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:06<00:06,  1.94it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:07<00:05,  2.01it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:07<00:05,  2.07it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:08<00:04,  2.32it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:08<00:03,  2.53it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:08<00:02,  2.70it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:09<00:02,  2.83it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:09<00:02,  2.85it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:09<00:01,  2.85it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:10<00:01,  2.94it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:10<00:01,  2.99it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:10<00:00,  3.06it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:11<00:00,  3.09it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:11<00:00,  3.13it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:11<00:00,  1.76it/s]
INFO:root:Time for 20 completions: 11.4 seconds
INFO:root:Saving all annotations to /u/hongli/.conda/envs/hongli/lib/python3.11/site-packages/alpaca_eval/evaluators_configs/oasst_pythia_12b/annotations_seed0_configs.json.
INFO:root:Loading all annotations from /u/hongli/.conda/envs/hongli/lib/python3.11/site-packages/alpaca_eval/evaluators_configs/oasst_pythia_12b/annotations_seed0_configs.json.
Annotation chunk: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:37<00:00, 97.28s/it]Annotation chunk: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:37<00:00, 97.28s/it]
INFO:root:Saving all results to example/dolly/oasst_pythia_12b
INFO:root:Not saving the result to the cached leaderboard because precomputed_leaderboard is not a path but <class 'NoneType'>.
        win_rate  standard_error  n_total  avg_length
oracle     40.00           11.24       20         584

------------------------------------------------------------
Sender: LSF System <lsfadmin@cccxc502.pok.ibm.com>
Subject: Job 3316703: <alpaca_eval --model_outputs example/dolly/oracle_responses.json --reference_outputs example/dolly/principle_responses.json --annotators_config oasst_pythia_12b> in cluster <cccCluster> Done

Job <alpaca_eval --model_outputs example/dolly/oracle_responses.json --reference_outputs example/dolly/principle_responses.json --annotators_config oasst_pythia_12b> was submitted from host <cccxl015> by user <hongli> in cluster <cccCluster> at Sat Jul  6 14:45:10 2024
Job was executed on host(s) <2*cccxc502>, in queue <x86_24h>, as user <hongli> in cluster <cccCluster> at Sat Jul  6 23:52:09 2024
</u/hongli> was used as the home directory.
</dccstor/rit_sva/hongli/alpaca_eval> was used as the working directory.
Started at Sat Jul  6 23:52:09 2024
Terminated at Sat Jul  6 23:54:28 2024
Results reported at Sat Jul  6 23:54:28 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
alpaca_eval --model_outputs example/dolly/oracle_responses.json --reference_outputs example/dolly/principle_responses.json --annotators_config oasst_pythia_12b
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   52.45 sec.
    Max Memory :                                 1004 MB
    Average Memory :                             624.55 MB
    Total Requested Memory :                     112640.00 MB
    Delta Memory :                               111636.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                12
    Run time :                                   138 sec.
    Turnaround time :                            32958 sec.

The output (if any) is above this job summary.

